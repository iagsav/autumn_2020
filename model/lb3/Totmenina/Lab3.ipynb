{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab3.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNWPznYZNqeSRgGGRV0IUwU"},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"hXU5ANZToPP9"},"source":["## **М19-ИВТ3**\n","## **Тотменина Елена**\n","## **Детектор - вариант 1**\n","## **Сеть - вариант 5**"]},{"cell_type":"markdown","metadata":{"id":"YqlE2af7o_dn"},"source":["### Подготовка: монтирование диска, загрузка и импорт модулей"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qoPvoMvS3nK3","executionInfo":{"status":"ok","timestamp":1607014357902,"user_tz":-180,"elapsed":20417,"user":{"displayName":"Лена Тотменина","photoUrl":"","userId":"09450321691879517445"}},"outputId":"12988aa4-e270-4d8c-a5ad-c7b7580044bb"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"46ZQ9vFWzUr5","executionInfo":{"status":"ok","timestamp":1607016889134,"user_tz":-180,"elapsed":723,"user":{"displayName":"Лена Тотменина","photoUrl":"","userId":"09450321691879517445"}}},"source":["from keras.models import Model\n","from keras.layers import Conv2D, Activation, Input, Add\n","from keras.layers.core import Dense, Flatten, Dropout\n","from keras.layers.pooling import MaxPooling2D\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","from keras.preprocessing import image\n","from sklearn.metrics.pairwise import cosine_similarity"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lEuVirTZ3erg"},"source":["### DeepID модель"]},{"cell_type":"code","metadata":{"id":"TWjqWnChxP5c","executionInfo":{"status":"ok","timestamp":1607016912357,"user_tz":-180,"elapsed":1101,"user":{"displayName":"Лена Тотменина","photoUrl":"","userId":"09450321691879517445"}}},"source":["def create_deepid_keras_model():\n","  myInput = Input(shape=(55, 47, 3))\n","  \n","  x = Conv2D(20, (4, 4), name='Conv1', activation='relu', input_shape=(55, 47, 3))(myInput)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool1')(x)\n","  x = Dropout(rate=0.99, name='D1')(x)\n","  \n","  x = Conv2D(40, (3, 3), name='Conv2', activation='relu')(x)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool2')(x)\n","  x = Dropout(rate=0.99, name='D2')(x)\n","  \n","  x = Conv2D(60, (3, 3), name='Conv3', activation='relu')(x)\n","  x = MaxPooling2D(pool_size=2, strides=2, name='Pool3')(x)\n","  x = Dropout(rate=0.99, name='D3')(x)\n","  \n","  x1 = Flatten()(x)\n","  fc11 = Dense(160, name = 'fc11')(x1)\n","  \n","  x2 = Conv2D(80, (2, 2), name='Conv4', activation='relu')(x)\n","  x2 = Flatten()(x2)\n","  fc12 = Dense(160, name = 'fc12')(x2)\n","  \n","  y = Add()([fc11, fc12])\n","  y = Activation('relu', name = 'deepid')(y)\n","  \n","  model = Model(inputs=[myInput], outputs=y)\n","\n","  return model"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dnB2CBQY3vi3"},"source":["### Нахождение лица с помощью классификатора haarcascade"]},{"cell_type":"code","metadata":{"id":"tSKPQtZ_yUKV","executionInfo":{"status":"ok","timestamp":1607016915574,"user_tz":-180,"elapsed":933,"user":{"displayName":"Лена Тотменина","photoUrl":"","userId":"09450321691879517445"}}},"source":["def detectFace(img, arr):\n","  target_size = (47, 55)\n","  face_cascade = cv2.CascadeClassifier(\"/content/drive/My Drive/Colab Notebooks/haarcascade_frontalface_default.xml\")\n","  faces = face_cascade.detectMultiScale(img, scaleFactor=1.1, minNeighbors=6, minSize=(20, 20))\n","\n","  if (len(faces) > 0):\n","    height, _ = img.shape[:2]\n","    x, y, w, h = faces[0]\n","    if y < (height / 2): \n","      arr.append(x)\n","      arr.append(y)\n","      detected_face = img[int(y):int(y+h), int(x):int(x+w)]\n","      detected_face = cv2.resize(detected_face, target_size)\n","      cv2.rectangle(img, (x, y), (x + w, y + h +5), (0, 0, 255), 3)\n","      img_pixels = image.img_to_array(detected_face)\n","      img_pixels = np.expand_dims(img_pixels, axis = 0)\n","\n","      if True:\n","        img_pixels /= 255 \n","      else:\n","        img_pixels /= 127.5\n","        img_pixels -= 1\n","\n","      return img_pixels"],"execution_count":15,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oJtqHgE44A7g"},"source":["### Тестирование"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nbZwYiPs2s-f","executionInfo":{"status":"ok","timestamp":1607016929332,"user_tz":-180,"elapsed":9349,"user":{"displayName":"Лена Тотменина","photoUrl":"","userId":"09450321691879517445"}},"outputId":"1353663f-5a64-4be2-8916-9edbdf6fbb2e"},"source":["video_path = ('/content/drive/My Drive/Colab Notebooks/camera1.mp4')\n","video = cv2.VideoCapture(video_path) \n","\n","model = create_deepid_keras_model()\n","model.load_weights(\"/content/drive/My Drive/Colab Notebooks/deepid_keras_weights.h5\")\n","\n","img_path = cv2.imread(\"/content/drive/My Drive/Colab Notebooks/test2.jpg\")\n","arr = []\n","img_reference = detectFace(img_path, arr)\n","source_img = model.predict(img_reference)\n","\n","while(True):\n","  grab, frame = video.read()\n","  if grab == False:\n","    break\n","\n","  arr = []\n","  find_face = detectFace(frame, arr)\n","\n","  if find_face is not None:\n","    predict_img = model.predict(find_face)\n","    cosine = cosine_similarity(source_img, predict_img)\n","    cv2.putText(frame, 'Similarity:{:.2f}'.format(cosine[0][0]), (arr[0], arr[1]),\n","    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 5)\n","\n","  cv2_imshow(frame)\n","\n","cv2.destroyAllWindows()"],"execution_count":16,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f0d88f71bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"}]}]}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим модель\n",
    "sp = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "imtest = io.imread('test1.jpg')\n",
    "imtest2 = io.imread('test2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Находим\n",
    "dets = detector(imtest, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "win1 = dlib.image_window()\n",
    "win1.clear_overlay()\n",
    "win1.set_image(imtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection 0: Left: 167 Top: 167 Right: 322 Bottom: 322\n"
     ]
    }
   ],
   "source": [
    "for k, d in enumerate(dets):\n",
    "    print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(\n",
    "        k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "    shape = sp(imtest, d)\n",
    "    win1.clear_overlay()\n",
    "    win1.add_overlay(d)\n",
    "    win1.add_overlay(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,Model\n",
    "from tensorflow.keras.layers import ZeroPadding2D,Convolution2D,MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense,Dropout,Softmax,Flatten,Activation,BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D((1,1),input_shape=(224,224, 3)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(ZeroPadding2D((1,1)))\n",
    "model.add(Convolution2D(512, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    " \n",
    "model.add(Convolution2D(4096, (7, 7), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(4096, (1, 1), activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(2622, (1, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Load VGG Face model weights\n",
    "model.load_weights('vgg_face_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_face=Model(inputs=model.layers[0].input,outputs=model.layers[-2].output) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 460, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = (224, 224)\n",
    "imtest = cv2.resize(imtest, dim, interpolation = cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "imtest = np.expand_dims(imtest, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.3422265,  9.906648 ,  7.9677815, ..., -2.3098629,  2.6143951,\n",
       "         1.2845223]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_face.predict(imtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# дескриптор\n",
    "def findCosineDistance(source_representation, test_representation):\n",
    "    a = np.matmul(np.transpose(source_representation), test_representation)\n",
    "    b = np.sum(np.multiply(source_representation, source_representation))\n",
    "    c = np.sum(np.multiply(test_representation, test_representation))\n",
    "    return 1 - (a / (np.sqrt(b) * np.sqrt(c)))\n",
    " \n",
    "def findEuclideanDistance(source_representation, test_representation):\n",
    "    euclidean_distance = source_representation - test_representation\n",
    "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
    "    euclidean_distance = np.sqrt(euclidean_distance)\n",
    "    return euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.40 #cosine similarity\n",
    "#epsilon = 120 #euclidean distance\n",
    " \n",
    "def verifyFace(img1, img2):\n",
    "    img1_representation = vgg_face.predict(img1)\n",
    "    img2_representation = vgg_face.predict(img2)\n",
    "#     img2_representation = vgg_face.predict(preprocess_image(img2))[0,:]\n",
    " \n",
    "#     cosine_similarity = findCosineDistance(img1_representation, img2_representation)\n",
    "    euclidean_distance = findEuclideanDistance(img1_representation, img2_representation)\n",
    "#     print(cosine_similarity)\n",
    "    print(euclidean_distance)\n",
    "    return(euclidean_distance)\n",
    "#     if(cosine_similarity &lt; epsilon):\n",
    "#         print(\"verified... they are same person\")\n",
    "#     else:\n",
    "#         print(\"unverified! they are not same person!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "verifyFace(imtest,imtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imtest = io.imread('test1.jpg')\n",
    "imtest2 = io.imread('test2.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1200, 3)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imtest2.shape)\n",
    "dim = (224, 224)\n",
    "imtest2 = cv2.resize(imtest2, dim, interpolation = cv2.INTER_AREA)\n",
    "print(imtest2.shape)\n",
    "imtest2 = np.expand_dims(imtest2, axis=0)\n",
    "print(imtest2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(460, 460, 3)\n",
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(imtest.shape)\n",
    "dim = (224, 224)\n",
    "imtest = cv2.resize(imtest, dim, interpolation = cv2.INTER_AREA)\n",
    "print(imtest.shape)\n",
    "imtest = np.expand_dims(imtest, axis=0)\n",
    "print(imtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.58502\n"
     ]
    }
   ],
   "source": [
    "verifyFace(imtest,imtest2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "ret, frame = cap.read()\n",
    "cv2.imshow(\"Capture\", frame)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    ch = cv2.waitKey(5)\n",
    "    if ch == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "imtest = io.imread('testMy.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n",
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "dim = (224, 224)\n",
    "print(imtest.shape)\n",
    "imtest = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "imtest = np.expand_dims(imtest, axis=0)\n",
    "print(imtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.155828\n",
      "15.37387\n",
      "16.13153\n"
     ]
    }
   ],
   "source": [
    "# Находим\n",
    "color = (255, 0, 0)\n",
    "while (True):\n",
    "    ret, frame = cap.read()\n",
    "    ch = cv2.waitKey(5)\n",
    "    # Находим\n",
    "    dets = detector(frame, 1)\n",
    "    for k, d in enumerate(dets):\n",
    "#         print(\"Detection {}: Left: {} Top: {} Right: {} Bottom: {}\".format(k, d.left(), d.top(), d.right(), d.bottom()))\n",
    "        frame = cv2.rectangle(frame, (d.left(), d.top()), (d.right(), d.bottom()), color, 2)\n",
    "        dim = (224, 224)\n",
    "        frameForVGG = cv2.resize(frame, dim, interpolation = cv2.INTER_AREA)\n",
    "        frameForVGG = np.expand_dims(frameForVGG, axis=0)\n",
    "        cv2.putText(frame, str(verifyFace(imtest,frameForVGG)), (d.left(), d.top()), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2)    \n",
    "    cv2.imshow(\"Capture\", frame)\n",
    "    ch = cv2.waitKey(5)\n",
    "    if ch == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
